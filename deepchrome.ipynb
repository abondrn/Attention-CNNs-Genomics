{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kipoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.8.2-cp38-cp38-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/anaconda3/lib/python3.8/site-packages (from torchvision) (1.18.5)\n",
      "Requirement already satisfied: torch==1.7.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from torchvision) (1.7.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from torchvision) (7.2.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/anaconda3/lib/python3.8/site-packages (from torch==1.7.1->torchvision) (3.7.4.2)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"AttentiveChrome/v2PyTorch/train.py\", line 20, in <module>\n",
      "    import data\n",
      "  File \"/Users/alex/Documents/prog/courses/compbio/Attention-CNNs-Genomics/AttentiveChrome/v2PyTorch/data.py\", line 8, in <module>\n",
      "    from torchvision import transforms, utils\n",
      "ModuleNotFoundError: No module named 'torchvision'\n"
     ]
    }
   ],
   "source": [
    "!python AttentiveChrome/v2PyTorch/train.py --test_on_saved_model --save_attention_maps --kipoi_model --pgd \\\n",
    "--save_root ./Results_E016_fgsm --save_adv_inputs --only_run_model 'E016'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>loading train data\n",
      "Number of genes: 62\n",
      "Number of entries: 1000\n",
      "Number of HMs: 7\n",
      "==>loading valid data\n",
      "Number of genes: 62\n",
      "Number of entries: 1000\n",
      "Number of HMs: 7\n",
      "==>loading test data\n",
      "Number of genes: 62\n",
      "Number of entries: 1000\n",
      "Number of HMs: 7\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def loadData(filename,windows):\n",
    "\twith open(filename) as fi:\n",
    "\t\tcsv_reader=csv.reader(fi)\n",
    "\t\tdata=list(csv_reader)\n",
    "\n",
    "\t\tncols=(len(data[0]))\n",
    "\tfi.close()\n",
    "\tnrows=len(data)\n",
    "\tngenes=nrows/windows\n",
    "\tnfeatures=ncols-1\n",
    "\tprint(\"Number of genes: %d\" % ngenes)\n",
    "\tprint(\"Number of entries: %d\" % nrows)\n",
    "\tprint(\"Number of HMs: %d\" % nfeatures)\n",
    "\n",
    "\tcount=0\n",
    "\tattr=collections.OrderedDict()\n",
    "\tXs = []\n",
    "\tys = []\n",
    "\n",
    "\tfor i in range(0,nrows,windows):\n",
    "\t\tshape = (windows,)\n",
    "\t\thm1=np.zeros(shape)\n",
    "\t\thm2=np.zeros(shape)\n",
    "\t\thm3=np.zeros(shape)\n",
    "\t\thm4=np.zeros(shape)\n",
    "\t\thm5=np.zeros(shape)\n",
    "\t\tfor w in range(0,windows):\n",
    "\t\t\tif not i+w < nrows:\n",
    "\t\t\t\tbreak\n",
    "\t\t\thm1[w]=int(data[i+w][2])\n",
    "\t\t\thm2[w]=int(data[i+w][3])\n",
    "\t\t\thm3[w]=int(data[i+w][4])\n",
    "\t\t\thm4[w]=int(data[i+w][5])\n",
    "\t\t\thm5[w]=int(data[i+w][6])\n",
    "\t\t\t\n",
    "\t\t\tthresholded_expr = int(data[i+w][7])\n",
    "\n",
    "\t\tXs.append([hm1, hm2, hm3, hm4, hm5])\n",
    "\t\tys.append(thresholded_expr)\n",
    "\n",
    "\treturn np.array(Xs), np.array(ys)\n",
    "\n",
    "def load_data(data_root, cell_type, n_bins=16, batch_size=16):\n",
    "\t'''\n",
    "\tLoads data into a 3D tensor for each of the 3 splits.\n",
    "\n",
    "\t'''\n",
    "\tprint(\"==>loading train data\")\n",
    "\ttrain=loadData(data_root+\"/\"+cell_type+\"/classification/train.csv\",n_bins)\n",
    "\n",
    "\tprint(\"==>loading valid data\")\n",
    "\tvalid=loadData(data_root+\"/\"+cell_type+\"/classification/valid.csv\",n_bins)\n",
    "\n",
    "\tprint(\"==>loading test data\")\n",
    "\ttest=loadData(data_root+\"/\"+cell_type+\"/classification/test.csv\",n_bins)\n",
    "\n",
    "\treturn train,valid,test\n",
    "\n",
    "#parser.add_argument('--data_root', type=str, default='./data/', help='data location')\n",
    "#parser.add_argument('--cell_type', type=str, default='E003', help='cell type 1')\n",
    "\n",
    "data = load_data('./AttentiveChrome/v2PyTorch/data', 'Toy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 5, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of numpy.core.overrides failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/numpy/core/overrides.py\", line 16, in <module>\n",
      "    add_docstring(\n",
      "RuntimeError: implement_array_function method already has a docstring\n",
      "]\n",
      "[autoreload of numpy.core.multiarray failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/numpy/core/multiarray.py\", line 18, in <module>\n",
      "    from ._multiarray_umath import (\n",
      "ImportError: cannot import name '_set_madvise_hugepage' from 'numpy.core._multiarray_umath' (/usr/local/anaconda3/lib/python3.8/site-packages/numpy/core/_multiarray_umath.cpython-38-darwin.so)\n",
      "]\n",
      "[autoreload of numpy.core._add_newdocs failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/numpy/core/_add_newdocs.py\", line 4397, in <module>\n",
      "    add_newdoc('numpy.core.multiarray', '_set_madvise_hugepage',\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/numpy/core/function_base.py\", line 497, in add_newdoc\n",
      "    new = getattr(__import__(place, globals(), {}, [obj]), obj)\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_set_madvise_hugepage'\n",
      "]\n",
      "[autoreload of numpy.matrixlib failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/numpy/matrixlib/__init__.py\", line 6, in <module>\n",
      "    __all__ = defmatrix.__all__\n",
      "NameError: name 'defmatrix' is not defined\n",
      "]\n",
      "[autoreload of numpy.lib failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/numpy/lib/__init__.py\", line 45, in <module>\n",
      "    __all__ += type_check.__all__\n",
      "NameError: name 'type_check' is not defined\n",
      "]\n",
      "[autoreload of numpy.ma.core failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 317, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 280, in update_instances\n",
      "    ref.__class__ = new\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/numpy/ma/core.py\", line 6535, in __setattr__\n",
      "    return super(MaskedConstant, self).__setattr__(attr, value)\n",
      "TypeError: super(type, obj): obj must be an instance or subtype of type\n",
      "]\n",
      "[autoreload of numpy failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/numpy/__init__.py\", line 273, in <module>\n",
      "    _mac_os_check()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/numpy/__init__.py\", line 264, in _mac_os_check\n",
      "    x = linspace(0, 2, 5)\n",
      "  File \"<__array_function__ internals>\", line 5, in linspace\n",
      "TypeError: an integer is required (got type _NoValueType)\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.4.0-cp38-cp38-macosx_10_11_x86_64.whl (175.5 MB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.2)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.19.4)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (1.24.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
      "Installing collected packages: tensorflow\n",
      "Successfully installed tensorflow-2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler, ReduceLROnPlateau\n",
    "\n",
    "# https://github.com/titu1994/keras-attention-augmented-convs/blob/master/attn_augconv.py\n",
    "# most of the implementation is taken from this repo\n",
    "# I extended to add 1-D CNN implementation.\n",
    "# Even though, it's (the extension) not tested properly yet.\n",
    "\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv_layer(filters, kernel_size, strides=(1, 1), padding='same', name=None):\n",
    "    return Conv2D(filters, kernel_size, strides=strides, padding=padding,\n",
    "                  use_bias=True, kernel_initializer='he_normal', name=name)\n",
    "\n",
    "\n",
    "def _conv_layer1d(ip, t_n, f_n, filters, kernel_size, strides=1, padding='same', name=None):\n",
    "    \n",
    "\n",
    "    conv1 = Conv1D(filters, kernel_size, strides=strides, padding=padding,\n",
    "                  use_bias=True, kernel_initializer='he_normal', name=name)(ip)\n",
    "    \n",
    "    reshape = Reshape((t_n, 1, filters))(conv1)\n",
    "    \n",
    "    return reshape\n",
    "\n",
    "\n",
    "\n",
    "def _conv_layer1r(ip, t_n, f_n, filters, kernel_size, strides=1, padding='same', name=None):\n",
    "    \n",
    "    reshape1 = Reshape((t_n, f_n))(ip)\n",
    "    \n",
    "\n",
    "    conv1 = Conv1D(filters, kernel_size, strides=strides, padding=padding,\n",
    "                  use_bias=True, kernel_initializer='he_normal', name=name)(reshape1)\n",
    "    \n",
    "    reshape2 = Reshape((t_n, 1, filters))(conv1)\n",
    "    \n",
    "    return reshape2\n",
    "\n",
    "\n",
    "def _normalize_depth_vars(depth_k, depth_v, filters):\n",
    "    \"\"\"\n",
    "    Accepts depth_k and depth_v as either floats or integers\n",
    "    and normalizes them to integers.\n",
    "    Args:\n",
    "        depth_k: float or int.\n",
    "        depth_v: float or int.\n",
    "        filters: number of output filters.\n",
    "    Returns:\n",
    "        depth_k, depth_v as integers.\n",
    "    \"\"\"\n",
    "\n",
    "    if type(depth_k) == float:\n",
    "        depth_k = int(filters * depth_k)\n",
    "    else:\n",
    "        depth_k = int(depth_k)\n",
    "\n",
    "    if type(depth_v) == float:\n",
    "        depth_v = int(filters * depth_v)\n",
    "    else:\n",
    "        depth_v = int(depth_v)\n",
    "\n",
    "    return depth_k, depth_v\n",
    "\n",
    "\n",
    "class AttentionAugmentation2D(Layer):\n",
    "\n",
    "    def __init__(self, depth_k, depth_v, num_heads, relative=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Applies attention augmentation on a convolutional layer\n",
    "        output.\n",
    "        Args:\n",
    "            depth_k: float or int. Number of filters for k.\n",
    "            Computes the number of filters for `v`.\n",
    "            If passed as float, computed as `filters * depth_k`.\n",
    "        depth_v: float or int. Number of filters for v.\n",
    "            Computes the number of filters for `k`.\n",
    "            If passed as float, computed as `filters * depth_v`.\n",
    "        num_heads: int. Number of attention heads.\n",
    "            Must be set such that `depth_k // num_heads` is > 0.\n",
    "        relative: bool, whether to use relative encodings.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: if depth_v or depth_k is not divisible by\n",
    "                num_heads.\n",
    "        Returns:\n",
    "            Output tensor of shape\n",
    "            -   [Batch, Height, Width, Depth_V] if\n",
    "                channels_last data format.\n",
    "            -   [Batch, Depth_V, Height, Width] if\n",
    "                channels_first data format.\n",
    "        \"\"\"\n",
    "        super(AttentionAugmentation2D, self).__init__(**kwargs)\n",
    "\n",
    "        if depth_k % num_heads != 0:\n",
    "            raise ValueError('`depth_k` (%d) is not divisible by `num_heads` (%d)' % (\n",
    "                depth_k, num_heads))\n",
    "\n",
    "        if depth_v % num_heads != 0:\n",
    "            raise ValueError('`depth_v` (%d) is not divisible by `num_heads` (%d)' % (\n",
    "                depth_v, num_heads))\n",
    "\n",
    "        if depth_k // num_heads < 1.:\n",
    "            raise ValueError('depth_k / num_heads cannot be less than 1 ! '\n",
    "                             'Given depth_k = %d, num_heads = %d' % (\n",
    "                             depth_k, num_heads))\n",
    "\n",
    "        if depth_v // num_heads < 1.:\n",
    "            raise ValueError('depth_v / num_heads cannot be less than 1 ! '\n",
    "                             'Given depth_v = %d, num_heads = %d' % (\n",
    "                                 depth_v, num_heads))\n",
    "\n",
    "        self.depth_k = depth_k\n",
    "        self.depth_v = depth_v\n",
    "        self.num_heads = num_heads\n",
    "        self.relative = relative\n",
    "\n",
    "        self.axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self._shape = input_shape\n",
    "\n",
    "        # normalize the format of depth_v and depth_k\n",
    "        self.depth_k, self.depth_v = _normalize_depth_vars(self.depth_k, self.depth_v,\n",
    "                                                           input_shape)\n",
    "\n",
    "        if self.axis == 1:\n",
    "            _, channels, height, width = input_shape\n",
    "        else:\n",
    "            _, height, width, channels = input_shape\n",
    "\n",
    "        if self.relative:\n",
    "            dk_per_head = self.depth_k // self.num_heads\n",
    "            \n",
    "            # print(dk_per_head)\n",
    "\n",
    "            if dk_per_head == 0:\n",
    "                print('dk per head', dk_per_head)\n",
    "\n",
    "            self.key_relative_w = self.add_weight('key_rel_w',\n",
    "                                                  shape=tf.TensorShape([2 * width - 1, dk_per_head]),\n",
    "                                                  initializer=initializers.RandomNormal(stddev=dk_per_head ** -0.5))\n",
    "            # 2 * width - 1\n",
    "\n",
    "            self.key_relative_h = self.add_weight('key_rel_h',\n",
    "                                                  shape=tf.TensorShape([2 * height - 1, dk_per_head]),\n",
    "                                                  initializer=initializers.RandomNormal(stddev=dk_per_head ** -0.5))\n",
    "            # 2 * height - 1\n",
    "\n",
    "        else:\n",
    "            self.key_relative_w = None\n",
    "            self.key_relative_h = None\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        if self.axis == 1:\n",
    "            # If channels first, force it to be channels last for these ops\n",
    "            inputs = K.permute_dimensions(inputs, [0, 2, 3, 1])\n",
    "\n",
    "        q, k, v = tf.split(inputs, [self.depth_k, self.depth_k, self.depth_v], axis=-1)\n",
    "\n",
    "        q = self.split_heads_2d(q)\n",
    "        k = self.split_heads_2d(k)\n",
    "        v = self.split_heads_2d(v)\n",
    "\n",
    "        # scale query\n",
    "        depth_k_heads = self.depth_k / self.num_heads\n",
    "        q *= (depth_k_heads ** -0.5)\n",
    "\n",
    "        # [Batch, num_heads, height * width, depth_k or depth_v] if axis == -1\n",
    "        qk_shape = [self._batch, self.num_heads, self._height * self._width, self.depth_k // self.num_heads]\n",
    "        v_shape = [self._batch, self.num_heads, self._height * self._width, self.depth_v // self.num_heads]\n",
    "        flat_q = K.reshape(q, K.stack(qk_shape))\n",
    "        flat_k = K.reshape(k, K.stack(qk_shape))\n",
    "        flat_v = K.reshape(v, K.stack(v_shape))\n",
    "\n",
    "        # [Batch, num_heads, HW, HW]\n",
    "        logits = tf.matmul(flat_q, flat_k, transpose_b=True)\n",
    "\n",
    "        # Apply relative encodings\n",
    "        if self.relative:\n",
    "            h_rel_logits, w_rel_logits = self.relative_logits(q)\n",
    "            logits += h_rel_logits\n",
    "            logits += w_rel_logits\n",
    "\n",
    "        weights = K.softmax(logits, axis=-1)\n",
    "        attn_out = tf.matmul(weights, flat_v)\n",
    "\n",
    "        attn_out_shape = [self._batch, self.num_heads, self._height, self._width, self.depth_v // self.num_heads]\n",
    "        attn_out_shape = K.stack(attn_out_shape)\n",
    "        attn_out = K.reshape(attn_out, attn_out_shape)\n",
    "        attn_out = self.combine_heads_2d(attn_out)\n",
    "        # [batch, height, width, depth_v]\n",
    "\n",
    "        if self.axis == 1:\n",
    "            # return to [batch, depth_v, height, width] for channels first\n",
    "            attn_out = K.permute_dimensions(attn_out, [0, 3, 1, 2])\n",
    "        \n",
    "        return attn_out\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_shape = list(input_shape)\n",
    "        output_shape[self.axis] = self.depth_v\n",
    "        return tuple(output_shape)\n",
    "\n",
    "    def split_heads_2d(self, ip):\n",
    "        tensor_shape = K.shape(ip)\n",
    "\n",
    "        # batch, height, width, channels for axis = -1\n",
    "        tensor_shape = [tensor_shape[i] for i in range(len(self._shape))]\n",
    "\n",
    "        batch = tensor_shape[0]\n",
    "        height = tensor_shape[1]\n",
    "        width = tensor_shape[2]\n",
    "        channels = tensor_shape[3]\n",
    "\n",
    "        # Save the spatial tensor dimensions\n",
    "        self._batch = batch\n",
    "        self._height = height\n",
    "        self._width = width\n",
    "\n",
    "        ret_shape = K.stack([batch, height, width,  self.num_heads, channels // self.num_heads])\n",
    "        split = K.reshape(ip, ret_shape)\n",
    "        transpose_axes = (0, 3, 1, 2, 4)\n",
    "        split = K.permute_dimensions(split, transpose_axes)\n",
    "\n",
    "        return split\n",
    "\n",
    "    def relative_logits(self, q):\n",
    "        shape = K.shape(q)\n",
    "        # [batch, num_heads, H, W, depth_v]\n",
    "        shape = [shape[i] for i in range(5)]\n",
    "\n",
    "        height = shape[2]\n",
    "        width = shape[3]\n",
    "\n",
    "        rel_logits_w = self.relative_logits_1d(q, self.key_relative_w, height, width,\n",
    "                                               transpose_mask=[0, 1, 2, 4, 3, 5])\n",
    "\n",
    "        rel_logits_h = self.relative_logits_1d(\n",
    "            K.permute_dimensions(q, [0, 1, 3, 2, 4]),\n",
    "            self.key_relative_h, width, height,\n",
    "            transpose_mask=[0, 1, 4, 2, 5, 3])\n",
    "\n",
    "        return rel_logits_h, rel_logits_w\n",
    "\n",
    "    def relative_logits_1d(self, q, rel_k, H, W, transpose_mask):\n",
    "        rel_logits = tf.einsum('bhxyd,md->bhxym', q, rel_k)\n",
    "        rel_logits = K.reshape(rel_logits, [-1, self.num_heads * H, W, 2 * W - 1])\n",
    "        rel_logits = self.rel_to_abs(rel_logits)\n",
    "        rel_logits = K.reshape(rel_logits, [-1, self.num_heads, H, W, W])\n",
    "        rel_logits = K.expand_dims(rel_logits, axis=3)\n",
    "        rel_logits = K.tile(rel_logits, [1, 1, 1, H, 1, 1])\n",
    "        rel_logits = K.permute_dimensions(rel_logits, transpose_mask)\n",
    "        rel_logits = K.reshape(rel_logits, [-1, self.num_heads, H * W, H * W])\n",
    "        return rel_logits\n",
    "\n",
    "    def rel_to_abs(self, x):\n",
    "        shape = K.shape(x)\n",
    "        shape = [shape[i] for i in range(3)]\n",
    "        B, Nh, L, = shape\n",
    "        col_pad = K.zeros(K.stack([B, Nh, L, 1]))\n",
    "        x = K.concatenate([x, col_pad], axis=3)\n",
    "        flat_x = K.reshape(x, [B, Nh, L * 2 * L])\n",
    "        flat_pad = K.zeros(K.stack([B, Nh, L - 1]))\n",
    "        flat_x_padded = K.concatenate([flat_x, flat_pad], axis=2)\n",
    "        final_x = K.reshape(flat_x_padded, [B, Nh, L + 1, 2 * L - 1])\n",
    "        final_x = final_x[:, :, :L, L - 1:]\n",
    "        return final_x\n",
    "\n",
    "    def combine_heads_2d(self, inputs):\n",
    "        # [batch, num_heads, height, width, depth_v // num_heads]\n",
    "        transposed = K.permute_dimensions(inputs, [0, 2, 3, 1, 4])\n",
    "        # [batch, height, width, num_heads, depth_v // num_heads]\n",
    "        shape = K.shape(transposed)\n",
    "        shape = [shape[i] for i in range(5)]\n",
    "\n",
    "        a, b = shape[-2:]\n",
    "        ret_shape = K.stack(shape[:-2] + [a * b])\n",
    "        # [batch, height, width, depth_v]\n",
    "        return K.reshape(transposed, ret_shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'depth_k': self.depth_k,\n",
    "            'depth_v': self.depth_v,\n",
    "            'num_heads': self.num_heads,\n",
    "            'relative': self.relative,\n",
    "        }\n",
    "        base_config = super(AttentionAugmentation2D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "def augmented_conv2d(ip, filters, kernel_size=(3, 3), strides=(1, 1),\n",
    "                     depth_k=0.2, depth_v=0.2, num_heads=8, relative_encodings=True):\n",
    "    \"\"\"\n",
    "    Builds an Attention Augmented Convolution block.\n",
    "    Args:\n",
    "        ip: keras tensor.\n",
    "        filters: number of output filters.\n",
    "        kernel_size: convolution kernel size.\n",
    "        strides: strides of the convolution.\n",
    "        depth_k: float or int. Number of filters for k.\n",
    "            Computes the number of filters for `v`.\n",
    "            If passed as float, computed as `filters * depth_k`.\n",
    "        depth_v: float or int. Number of filters for v.\n",
    "            Computes the number of filters for `k`.\n",
    "            If passed as float, computed as `filters * depth_v`.\n",
    "        num_heads: int. Number of attention heads.\n",
    "            Must be set such that `depth_k // num_heads` is > 0.\n",
    "        relative_encodings: bool. Whether to use relative\n",
    "            encodings or not.\n",
    "    Returns:\n",
    "        a keras tensor.\n",
    "    \"\"\"\n",
    "    # input_shape = K.int_shape(ip)\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    depth_k, depth_v = _normalize_depth_vars(depth_k, depth_v, filters)\n",
    "\n",
    "    conv_out = _conv_layer(filters - depth_v, kernel_size, strides)(ip)\n",
    "\n",
    "    # Augmented Attention Block\n",
    "    qkv_conv = _conv_layer(2 * depth_k + depth_v, (1, 1), strides)(ip)\n",
    "    attn_out = AttentionAugmentation2D(depth_k, depth_v, num_heads, relative_encodings)(qkv_conv)\n",
    "    attn_out = _conv_layer(depth_v, kernel_size=(1, 1))(attn_out)\n",
    "\n",
    "    output = concatenate([conv_out, attn_out], axis=channel_axis)\n",
    "    return output\n",
    "\n",
    "def augmented_conv1d(ip, shape, filters, kernel_size=3, strides=1, padding = 'same',\n",
    "                     depth_k=0.2, depth_v=0.2, num_heads=2, relative_encodings=True):\n",
    "    \"\"\"\n",
    "    Builds an Attention Augmented Convolution block.\n",
    "    Args:\n",
    "        ip: keras tensor.\n",
    "        filters: number of output filters.\n",
    "        kernel_size: convolution kernel size.\n",
    "        strides: strides of the convolution.\n",
    "        depth_k: float or int. Number of filters for k.\n",
    "            Computes the number of filters for `v`.\n",
    "            If passed as float, computed as `filters * depth_k`.\n",
    "        depth_v: float or int. Number of filters for v.\n",
    "            Computes the number of filters for `k`.\n",
    "            If passed as float, computed as `filters * depth_v`.\n",
    "        num_heads: int. Number of attention heads.\n",
    "            Must be set such that `depth_k // num_heads` is > 0.\n",
    "        relative_encodings: bool. Whether to use relative\n",
    "            encodings or not.\n",
    "    Returns:\n",
    "        a keras tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    if type(kernel_size) == int:\n",
    "        pass\n",
    "    else:\n",
    "        kernel_size = kernel_size[0]\n",
    "        \n",
    "    if type(strides) == int:\n",
    "        pass\n",
    "    else:\n",
    "        strides = strides[0]\n",
    "        \n",
    "    t_n = shape[0]\n",
    "    f_n = shape[1]\n",
    "        \n",
    "    # input_shape = K.int_shape(ip)\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    depth_k, depth_v = _normalize_depth_vars(depth_k, depth_v, filters)\n",
    "    \n",
    "    # print(kernel_size)\n",
    "    # print(strides)\n",
    "\n",
    "    conv_out = _conv_layer1d(ip, t_n, f_n, filters - depth_v, kernel_size, strides, padding = 'same')\n",
    "\n",
    "    # Augmented Attention Block\n",
    "    qkv_conv = _conv_layer1d(ip, t_n, f_n,  2 * depth_k + depth_v, 1, strides, padding = 'same')\n",
    "    attn_out = AttentionAugmentation2D(depth_k, depth_v, num_heads, relative_encodings)(qkv_conv)\n",
    "    attn_out = _conv_layer1r(attn_out, t_n, depth_v,  depth_v, 1, strides, padding = 'same')\n",
    "\n",
    "    output = Concatenate(axis=channel_axis)([conv_out, attn_out])\n",
    "   \n",
    "    reshape = Reshape((t_n, filters))(output)\n",
    "\n",
    "    return reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Neural Network Settings \n",
    "## CNN Base Function\n",
    "#@tf.function\n",
    "def create_nn(N = 1, num_filters = 8, \n",
    "              dense_neurons = 8,\n",
    "              conv_kernel_size = 5, \n",
    "              num_convolutions = 2,\n",
    "              cnn_to_fc_op = \"flatten\",  #\"flatten\", \"global_pool\",\n",
    "              dropout_rate = 0.4):\n",
    "  \n",
    "    inputShape = (N, 1)\n",
    "    chanDim = -1\n",
    "\n",
    "    # define the model input\n",
    "    inputs = Input(shape=inputShape)\n",
    "    x = inputs\n",
    "    # x = BatchNormalization(axis=chanDim)(x)\n",
    "\n",
    "    # # Perform multiple convolutional layers\n",
    "    ## TODO: explore tuning of these options\n",
    "    x = augmented_conv1d(x, shape = (N, 1), filters=num_filters, kernel_size=conv_kernel_size,\n",
    "                     strides = 1,\n",
    "                     padding = 'same', # if causal convolution is needed\n",
    "                     depth_k=2, depth_v=2,  \n",
    "                     num_heads=2, relative_encodings=True)\n",
    "    #x = BatchNormalization(axis=chanDim)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    if cnn_to_fc_op == \"flatten\":\n",
    "        x = Flatten()(x)\n",
    "    elif cnn_to_fc_op == \"global_pool\":\n",
    "        x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    else: \n",
    "        print(\"Use supported method for tensor decomposition\")\n",
    "\n",
    "\n",
    "    ## TODO: this is tunable\n",
    "    x = Dense(dense_neurons, activation='relu')(x) \n",
    "    x = BatchNormalization(axis=chanDim)(x) \n",
    "\n",
    "    ## Output layer for binary classification will be one neuron (sigmoid act)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # construct the NN\n",
    "    model = Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "## Neural Network Settings \n",
    "\n",
    "## Optimization settings:\n",
    "num_epochs = 2000\n",
    "batch_size = 512 \n",
    "learning_rate = 1e-2\n",
    "#lr_schedule = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "## stop the model if no validation improvement in patience epochs\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='train_loss', \n",
    "                                                      min_delta=0.0001, \n",
    "                                                      patience=50)\n",
    "\n",
    "## Directly Tunable architecture hyperparameters:\n",
    "dropout_rate = 0.4\n",
    "num_filters = 128\n",
    "conv_kernel_size = 5\n",
    "num_convolutions = 1\n",
    "# recall N is the input length.  N*N_dense_multiplier for feed-forward layers\n",
    "dense_neurons = 24\n",
    "\n",
    "## logistics\n",
    "#filepath = run_name+\"model-{epoch:02d}.hdf5\"\n",
    "#checkpoint = ModelCheckpoint(filepath, verbose=0, save_best_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 5, 1)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 5, 6)         12          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_24 (Reshape)            (None, 5, 1, 6)      0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_augmentation2d_7 (Att (None, None, None, N 10          reshape_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_25 (Reshape)            (None, 5, 2)         0           attention_augmentation2d_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 5, 4)         16          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 5, 2)         6           reshape_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_23 (Reshape)            (None, 5, 1, 4)      0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_26 (Reshape)            (None, 5, 1, 2)      0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 5, 1, 6)      0           reshape_23[0][0]                 \n",
      "                                                                 reshape_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_27 (Reshape)            (None, 5, 6)         0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 5, 6)         0           reshape_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 30)           0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            31          flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 75\n",
      "Trainable params: 75\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ip = Input(shape=(N,1))\n",
    "\n",
    "x = augmented_conv1d(ip, shape = (N, 1), filters=6, kernel_size=3,\n",
    "                     strides = 1,\n",
    "                     padding = 'same', # if causal convolution is needed\n",
    "                     depth_k=2, depth_v=2,  \n",
    "                     num_heads=2, relative_encodings=True)\n",
    "x = Activation('relu')(x)\n",
    "fl = Flatten()(x)\n",
    "fc = Dense(1, activation='sigmoid')(fl)\n",
    "\n",
    "aac_cnn = Model(ip, fc)\n",
    "\n",
    "aac_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "aac_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 5, 1)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 5, 6)         12          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)            (None, 5, 1, 6)      0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_augmentation2d_6 (Att (None, None, None, N 10          reshape_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_20 (Reshape)            (None, 5, 2)         0           attention_augmentation2d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 5, 126)       756         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 5, 2)         6           reshape_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)            (None, 5, 1, 126)    0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_21 (Reshape)            (None, 5, 1, 2)      0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 5, 1, 128)    0           reshape_18[0][0]                 \n",
      "                                                                 reshape_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_22 (Reshape)            (None, 5, 128)       0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 5, 128)       0           reshape_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 5, 128)       0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 2, 128)       0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 256)          0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 24)           6168        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 24)           96          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            25          batch_normalization_1[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 7,073\n",
      "Trainable params: 7,025\n",
      "Non-trainable params: 48\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Run the NN model\n",
    "callbacks_list = [earlystop_callback]#checkpoint, earlystop_callback] #, tensorboard]#, reduce_lr]#, earlystopping]\n",
    "\n",
    "N = 5\n",
    "\n",
    "model = create_nn(N, \n",
    "                  num_filters, \n",
    "                  dense_neurons = dense_neurons,\n",
    "                  conv_kernel_size = conv_kernel_size, \n",
    "                  num_convolutions = num_convolutions, \n",
    "                  cnn_to_fc_op = \"flatten\",\n",
    "                  dropout_rate = dropout_rate)\n",
    "\n",
    "opt = Adam(lr=learning_rate)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics = ['acc'], experimental_run_tf_function=False)#metrics=['acc', tf.keras.metrics.AUC()])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-d97bc7bf262e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maac_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maac_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maac_hist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m     return func.fit(\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m                          '`validation_data` is None.')\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m     return fit_generator(\n\u001b[0m\u001b[1;32m    772\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;31m# as Eager is expected to be taken.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m       output_dict = training_eager_v1.train_on_batch(\n\u001b[0m\u001b[1;32m   1071\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_eager_v1.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_utils_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_to_model_input_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m   outs, total_loss, output_losses, masks = (\n\u001b[0;32m--> 311\u001b[0;31m       _process_single_batch(\n\u001b[0m\u001b[1;32m    312\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m           \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_eager_v1.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    250\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mno\u001b[0m \u001b[0mloss\u001b[0m \u001b[0mto\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m   \"\"\"\n\u001b[0;32m--> 252\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager_learning_phase_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m       \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36meager_learning_phase_scope\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    571\u001b[0m   \u001b[0;32mglobal\u001b[0m \u001b[0m_GRAPH_LEARNING_PHASES\u001b[0m  \u001b[0;31m# pylint: disable=global-variable-not-assigned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m   \u001b[0;32massert\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m   \u001b[0mglobal_learning_phase_was_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_learning_phase_is_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mglobal_learning_phase_was_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "aac_hist = aac_cnn.fit(data[0][0], data[0][1], epochs = 2, batch_size = 16, validation_split = 0.5, verbose = 0)\n",
    "aac_hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(xTrain, yTrain,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    class_weight=class_weight,\n",
    "                    validation_data= (xValidation, yValidation),\n",
    "                    callbacks=callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbasecondaf1e5bcae88af4e02a963c01f952d7725"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
